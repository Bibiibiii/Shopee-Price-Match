{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model meredith.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vHdCS49-1mZl"},"source":["Reference:\n","https://arxiv.org/pdf/1801.07698.pdf\n","\n","https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\n","\n","https://www.kaggle.com/ragnar123/bert-baseline/comments\n","\n","https://www.kaggle.com/musha2017/shopee-external-models"]},{"cell_type":"markdown","metadata":{"id":"N_oz7jeDW1Tc"},"source":["load the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxqocG2eC9pj","executionInfo":{"status":"ok","timestamp":1622737197027,"user_tz":300,"elapsed":110,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"0109bd89-b4c9-4b59-9c28-d79d93961280"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkMUj18_pPv4","executionInfo":{"status":"ok","timestamp":1622737200180,"user_tz":300,"elapsed":2208,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"fa44412d-f55a-4e5f-9cd5-08412170494c"},"source":["!pip install bert-tensorflow==1.0.1\n","# downgrade bert to have gfile function"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bert-tensorflow==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDHSIgevq6EN","executionInfo":{"status":"ok","timestamp":1622737213568,"user_tz":300,"elapsed":2312,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"028e626c-f96d-4f4c-8211-f9499896417a"},"source":["!pip install tensorflow==2.3.0\n","# downgrade tensorflow --- some functions library changed"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.12.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n","Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.18.5)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.36.2)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.3.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.34.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.5.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.12.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.3.0) (57.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.30.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Usbxg1DwfgEa"},"source":["from shutil import copyfile\n","import re\n","import os\n","import numpy as np\n","import pandas as pd\n","import random\n","import math\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import warnings\n","warnings.simplefilter('ignore')\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import backend as K\n","t_path = '/content/drive/Shareddrives/deep learning project/data/shopee-external-models/tokenization.py'\n","copyfile(src = \"/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/shopee-external-models/tokenization.py\", dst = \"../content/tokenization.py\")\n","from bert import tokenization\n","import tensorflow_hub as hub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iY5oj0jgW0Lx","executionInfo":{"status":"ok","timestamp":1622737217421,"user_tz":300,"elapsed":4,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"6ff09b5b-1e8a-44db-e5c9-aba4d11e2a29"},"source":["# set work dictionary\n","print('Working Directory')\n","print(os.getcwd())\n","work_dir = \"/content/drive/Shareddrives/deep learning project/data/shopee-product-matching\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Working Directory\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HIinpRRuW0ON"},"source":["# import train and test in csv\n","test = pd.read_csv('/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/test.csv')\n","train = pd.read_csv('/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/train.csv')\n","# set image dataset path\n","test_paths = '/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/test_images'\n","train_paths = '/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/train_images'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vI9y6sjIXC8l","executionInfo":{"status":"ok","timestamp":1622737219107,"user_tz":300,"elapsed":182,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"4383b88c-aaf6-4e73-ec18-edfe85ad61fc"},"source":["train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34250, 5)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"IBByk6xkaPAu"},"source":["According to the kaggle, image_phrash < image < postion id.\n","\n","There are same pictures with different name;\n","\n","There are repeat pictures."]},{"cell_type":"code","metadata":{"id":"TSN1eRA39Wo4"},"source":["# add file path in the table (where to find the images)\n","train['path'] = '/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/train_images/' + train['image']\n","test['path'] = '/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/test_images/' + test['image']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lTUKn0p-KO3"},"source":["### set f1 score"]},{"cell_type":"code","metadata":{"id":"BYsyPkTd-Ogs"},"source":["def F1_score(target_column, pred_column): \n","    def get_f1(row):\n","        # Find the common values in target and prediction arrays.\n","        intersection = len( np.intersect1d(row[target_column], row[pred_column]) )\n","        # Computes the score by following the formula\n","        f1_score = 2 * intersection / (len(row[target_column]) + len(row[pred_column]))\n","        return f1_score\n","    return get_f1\n","# reference: stackflow"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-KFw8zS67Ix"},"source":["### Text Embeddings on title (BERT)"]},{"cell_type":"code","metadata":{"id":"LAPgQFCCfgQ2"},"source":["# Configuration\n","EPOCHS = 25\n","BATCH_SIZE = 32\n","# Seed\n","SEED = 123\n","# Verbosity\n","VERBOSE = 1\n","LR = 0.00001 # changed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kgf3UeWzfgUQ"},"source":["# Function to seed everything\n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    tf.random.set_seed(seed)\n","    \n","def read_and_preprocess():\n","    df = pd.read_csv('/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/train.csv')\n","    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n","    df['matches'] = df['label_group'].map(tmp)\n","    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n","    encoder = LabelEncoder()\n","    df['label_group'] = encoder.fit_transform(df['label_group'])\n","    N_CLASSES = df['label_group'].nunique()\n","    print(f'We have {N_CLASSES} classes')\n","    x_train, x_val, y_train, y_val = train_test_split(df[['title']], df['label_group'], shuffle = True, stratify = df['label_group'], random_state = SEED, test_size = 0.33)\n","    return df, N_CLASSES, x_train, x_val, y_train, y_val\n","\n","# Return tokens, masks and segments from a text array or series\n","def bert_encode(texts, tokenizer, max_len=512):\n","    all_tokens = []\n","    all_masks = []\n","    all_segments = []\n","    \n","    for text in texts:\n","        text = tokenizer.tokenize(text)\n","            \n","        text = text[:max_len-2]\n","        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n","        pad_len = max_len - len(input_sequence)\n","        \n","        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n","        tokens += [0] * pad_len\n","        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n","        segment_ids = [0] * max_len\n","        \n","        all_tokens.append(tokens)\n","        all_masks.append(pad_masks)\n","        all_segments.append(segment_ids)\n","    \n","    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruEkO6AXnvlP"},"source":["class ArcMarginProduct(tf.keras.layers.Layer):\n","\n","    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n","                 ls_eps=0.0, **kwargs):\n","\n","        super(ArcMarginProduct, self).__init__(**kwargs)\n","\n","        self.n_classes = n_classes\n","        self.s = s\n","        self.m = m\n","        self.ls_eps = ls_eps\n","        self.easy_margin = easy_margin\n","        self.cos_m = tf.math.cos(m)\n","        self.sin_m = tf.math.sin(m)\n","        self.th = tf.math.cos(math.pi - m)\n","        self.mm = tf.math.sin(math.pi - m) * m\n","\n","    def get_config(self):\n","\n","        config = super().get_config().copy()\n","        config.update({\n","            'n_classes': self.n_classes,\n","            's': self.s,\n","            'm': self.m,\n","            'ls_eps': self.ls_eps,\n","            'easy_margin': self.easy_margin,\n","        })\n","        return config\n","\n","    def build(self, input_shape):\n","        super(ArcMarginProduct, self).build(input_shape[0])\n","\n","        self.W = self.add_weight(\n","            name='W',\n","            shape=(int(input_shape[0][-1]), self.n_classes),\n","            initializer='glorot_uniform',\n","            dtype='float32',\n","            trainable=True,\n","            regularizer=None)\n","\n","    def call(self, inputs):\n","        X, y = inputs\n","        y = tf.cast(y, dtype=tf.int32)\n","        cosine = tf.matmul(\n","            tf.math.l2_normalize(X, axis=1),\n","            tf.math.l2_normalize(self.W, axis=0)\n","        )\n","        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        if self.easy_margin:\n","            phi = tf.where(cosine > 0, phi, cosine)\n","        else:\n","            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n","        one_hot = tf.cast(\n","            tf.one_hot(y, depth=self.n_classes),\n","            dtype=cosine.dtype\n","        )\n","        if self.ls_eps > 0:\n","            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n","\n","        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n","        output *= self.s\n","        return output\n","\n","# Function to build bert model\n","def build_bert_model(bert_layer, max_len = 512):\n","    \n","    margin = ArcMarginProduct(\n","            n_classes = N_CLASSES, \n","            s = 30, \n","            m = 0.5, \n","            name='head/arc_margin', \n","            dtype='float32'\n","            )\n","    \n","    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","    label = tf.keras.layers.Input(shape = (), name = 'label')\n","\n","    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    clf_output = sequence_output[:, 0, :]\n","    x = margin([clf_output, label])\n","    output = tf.keras.layers.Softmax(dtype='float32')(x)\n","    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n","    model.compile(optimizer = tf.keras.optimizers.Adam(lr = LR),\n","                  loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n","                  metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n","    return model\n","\n","def load_train_and_evaluate(x_train, x_val, y_train, y_val):\n","    seed_everything(SEED)\n","    # Load BERT from the Tensorflow Hub\n","    module_url = \"/content/drive/Shareddrives/deep learning project/data/shopee-product-matching/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n","    bert_layer = hub.KerasLayer(module_url, trainable = True)\n","    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n","    x_train = bert_encode(x_train['title'].values, tokenizer, max_len = 70)\n","    x_val = bert_encode(x_val['title'].values, tokenizer, max_len = 70)\n","    y_train = y_train.values\n","    y_val = y_val.values\n","    # Add targets to train and val\n","    x_train = (x_train[0], x_train[1], x_train[2], y_train)\n","    x_val = (x_val[0], x_val[1], x_val[2], y_val)\n","    bert_model = build_bert_model(bert_layer, max_len = 70)\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'Bert_{SEED}.h5', \n","                                                    monitor = 'val_loss', \n","                                                    verbose = VERBOSE, \n","                                                    save_best_only = True,\n","                                                    save_weights_only = True, \n","                                                    mode = 'min')\n","    history = bert_model.fit(x_train, y_train,\n","                             validation_data = (x_val, y_val),\n","                             epochs = EPOCHS, \n","                             callbacks = [checkpoint],\n","                             batch_size = BATCH_SIZE,\n","                             verbose = VERBOSE)\n","    return bert_model,history\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xmL7Co8sK6O","executionInfo":{"status":"ok","timestamp":1622737240122,"user_tz":300,"elapsed":171,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"0c5ad2d6-ae67-401a-95bd-f78b865b75a3"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","# use version 1 tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lT03PN9noTPB","executionInfo":{"status":"ok","timestamp":1622737242152,"user_tz":300,"elapsed":1312,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"7c548fc4-d0e7-48d7-d996-785a46db3ebc"},"source":["df, N_CLASSES, x_train, x_val, y_train, y_val = read_and_preprocess()\n","# process data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["We have 11014 classes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCpQdI71t_Gf","executionInfo":{"status":"ok","timestamp":1622754503234,"user_tz":300,"elapsed":17260549,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"115bca6a-2914-4ed2-cd61-9890b615bd7d"},"source":["#evaluate the train model\n","bert_model  = load_train_and_evaluate(x_train, x_val, y_train, y_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","718/718 [==============================] - ETA: 0s - loss: 23.9041 - sparse_categorical_accuracy: 0.0000e+00\n","Epoch 00001: val_loss improved from inf to 23.48550, saving model to Bert_123.h5\n","718/718 [==============================] - 690s 961ms/step - loss: 23.9041 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.4855 - val_sparse_categorical_accuracy: 0.0000e+00\n","Epoch 2/25\n","718/718 [==============================] - ETA: 0s - loss: 22.7323 - sparse_categorical_accuracy: 0.0000e+00\n","Epoch 00002: val_loss improved from 23.48550 to 22.67866, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 22.7323 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.6787 - val_sparse_categorical_accuracy: 1.7694e-04\n","Epoch 3/25\n","718/718 [==============================] - ETA: 0s - loss: 21.3282 - sparse_categorical_accuracy: 0.0037\n","Epoch 00003: val_loss improved from 22.67866 to 21.88824, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 21.3282 - sparse_categorical_accuracy: 0.0037 - val_loss: 21.8882 - val_sparse_categorical_accuracy: 0.0050\n","Epoch 4/25\n","718/718 [==============================] - ETA: 0s - loss: 19.7765 - sparse_categorical_accuracy: 0.0088\n","Epoch 00004: val_loss improved from 21.88824 to 21.15786, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 19.7765 - sparse_categorical_accuracy: 0.0088 - val_loss: 21.1579 - val_sparse_categorical_accuracy: 0.0107\n","Epoch 5/25\n","718/718 [==============================] - ETA: 0s - loss: 18.1811 - sparse_categorical_accuracy: 0.0194\n","Epoch 00005: val_loss improved from 21.15786 to 20.49544, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 18.1811 - sparse_categorical_accuracy: 0.0194 - val_loss: 20.4954 - val_sparse_categorical_accuracy: 0.0188\n","Epoch 6/25\n","718/718 [==============================] - ETA: 0s - loss: 16.6022 - sparse_categorical_accuracy: 0.0357\n","Epoch 00006: val_loss improved from 20.49544 to 19.90918, saving model to Bert_123.h5\n","718/718 [==============================] - 689s 960ms/step - loss: 16.6022 - sparse_categorical_accuracy: 0.0357 - val_loss: 19.9092 - val_sparse_categorical_accuracy: 0.0287\n","Epoch 7/25\n","718/718 [==============================] - ETA: 0s - loss: 15.0919 - sparse_categorical_accuracy: 0.0578\n","Epoch 00007: val_loss improved from 19.90918 to 19.38867, saving model to Bert_123.h5\n","718/718 [==============================] - 689s 960ms/step - loss: 15.0919 - sparse_categorical_accuracy: 0.0578 - val_loss: 19.3887 - val_sparse_categorical_accuracy: 0.0387\n","Epoch 8/25\n","718/718 [==============================] - ETA: 0s - loss: 13.6697 - sparse_categorical_accuracy: 0.0829\n","Epoch 00008: val_loss improved from 19.38867 to 18.94023, saving model to Bert_123.h5\n","718/718 [==============================] - 689s 960ms/step - loss: 13.6697 - sparse_categorical_accuracy: 0.0829 - val_loss: 18.9402 - val_sparse_categorical_accuracy: 0.0500\n","Epoch 9/25\n","718/718 [==============================] - ETA: 0s - loss: 12.3550 - sparse_categorical_accuracy: 0.1085\n","Epoch 00009: val_loss improved from 18.94023 to 18.53447, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 12.3550 - sparse_categorical_accuracy: 0.1085 - val_loss: 18.5345 - val_sparse_categorical_accuracy: 0.0587\n","Epoch 10/25\n","718/718 [==============================] - ETA: 0s - loss: 11.0978 - sparse_categorical_accuracy: 0.1405\n","Epoch 00010: val_loss improved from 18.53447 to 18.17242, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 11.0978 - sparse_categorical_accuracy: 0.1405 - val_loss: 18.1724 - val_sparse_categorical_accuracy: 0.0686\n","Epoch 11/25\n","718/718 [==============================] - ETA: 0s - loss: 9.9160 - sparse_categorical_accuracy: 0.1805\n","Epoch 00011: val_loss improved from 18.17242 to 17.82722, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 9.9160 - sparse_categorical_accuracy: 0.1805 - val_loss: 17.8272 - val_sparse_categorical_accuracy: 0.0771\n","Epoch 12/25\n","718/718 [==============================] - ETA: 0s - loss: 8.8380 - sparse_categorical_accuracy: 0.2223\n","Epoch 00012: val_loss improved from 17.82722 to 17.52291, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 8.8380 - sparse_categorical_accuracy: 0.2223 - val_loss: 17.5229 - val_sparse_categorical_accuracy: 0.0858\n","Epoch 13/25\n","718/718 [==============================] - ETA: 0s - loss: 7.8219 - sparse_categorical_accuracy: 0.2720\n","Epoch 00013: val_loss improved from 17.52291 to 17.24455, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 7.8219 - sparse_categorical_accuracy: 0.2720 - val_loss: 17.2446 - val_sparse_categorical_accuracy: 0.0941\n","Epoch 14/25\n","718/718 [==============================] - ETA: 0s - loss: 6.9294 - sparse_categorical_accuracy: 0.3261\n","Epoch 00014: val_loss improved from 17.24455 to 17.03508, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 6.9294 - sparse_categorical_accuracy: 0.3261 - val_loss: 17.0351 - val_sparse_categorical_accuracy: 0.0985\n","Epoch 15/25\n","718/718 [==============================] - ETA: 0s - loss: 6.1116 - sparse_categorical_accuracy: 0.3801\n","Epoch 00015: val_loss improved from 17.03508 to 16.75870, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 6.1116 - sparse_categorical_accuracy: 0.3801 - val_loss: 16.7587 - val_sparse_categorical_accuracy: 0.1077\n","Epoch 16/25\n","718/718 [==============================] - ETA: 0s - loss: 5.0656 - sparse_categorical_accuracy: 0.4645\n","Epoch 00016: val_loss improved from 16.75870 to 16.57341, saving model to Bert_123.h5\n","718/718 [==============================] - 687s 957ms/step - loss: 5.0656 - sparse_categorical_accuracy: 0.4645 - val_loss: 16.5734 - val_sparse_categorical_accuracy: 0.1143\n","Epoch 17/25\n","718/718 [==============================] - ETA: 0s - loss: 4.3410 - sparse_categorical_accuracy: 0.5370\n","Epoch 00017: val_loss improved from 16.57341 to 16.41138, saving model to Bert_123.h5\n","718/718 [==============================] - 687s 957ms/step - loss: 4.3410 - sparse_categorical_accuracy: 0.5370 - val_loss: 16.4114 - val_sparse_categorical_accuracy: 0.1199\n","Epoch 18/25\n","718/718 [==============================] - ETA: 0s - loss: 3.7811 - sparse_categorical_accuracy: 0.6137\n","Epoch 00018: val_loss improved from 16.41138 to 16.23336, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 3.7811 - sparse_categorical_accuracy: 0.6137 - val_loss: 16.2334 - val_sparse_categorical_accuracy: 0.1295\n","Epoch 19/25\n","718/718 [==============================] - ETA: 0s - loss: 3.2276 - sparse_categorical_accuracy: 0.6977\n","Epoch 00019: val_loss improved from 16.23336 to 16.07644, saving model to Bert_123.h5\n","718/718 [==============================] - 689s 960ms/step - loss: 3.2276 - sparse_categorical_accuracy: 0.6977 - val_loss: 16.0764 - val_sparse_categorical_accuracy: 0.1369\n","Epoch 20/25\n","718/718 [==============================] - ETA: 0s - loss: 2.6651 - sparse_categorical_accuracy: 0.7938\n","Epoch 00020: val_loss improved from 16.07644 to 15.93139, saving model to Bert_123.h5\n","718/718 [==============================] - 688s 958ms/step - loss: 2.6651 - sparse_categorical_accuracy: 0.7938 - val_loss: 15.9314 - val_sparse_categorical_accuracy: 0.1449\n","Epoch 21/25\n","718/718 [==============================] - ETA: 0s - loss: 2.1827 - sparse_categorical_accuracy: 0.8722\n","Epoch 00021: val_loss improved from 15.93139 to 15.78686, saving model to Bert_123.h5\n","718/718 [==============================] - 687s 957ms/step - loss: 2.1827 - sparse_categorical_accuracy: 0.8722 - val_loss: 15.7869 - val_sparse_categorical_accuracy: 0.1539\n","Epoch 22/25\n","718/718 [==============================] - ETA: 0s - loss: 1.7753 - sparse_categorical_accuracy: 0.9228\n","Epoch 00022: val_loss improved from 15.78686 to 15.65185, saving model to Bert_123.h5\n","718/718 [==============================] - 686s 956ms/step - loss: 1.7753 - sparse_categorical_accuracy: 0.9228 - val_loss: 15.6518 - val_sparse_categorical_accuracy: 0.1560\n","Epoch 23/25\n","718/718 [==============================] - ETA: 0s - loss: 1.4338 - sparse_categorical_accuracy: 0.9532\n","Epoch 00023: val_loss improved from 15.65185 to 15.55540, saving model to Bert_123.h5\n","718/718 [==============================] - 686s 956ms/step - loss: 1.4338 - sparse_categorical_accuracy: 0.9532 - val_loss: 15.5554 - val_sparse_categorical_accuracy: 0.1616\n","Epoch 24/25\n","718/718 [==============================] - ETA: 0s - loss: 1.1219 - sparse_categorical_accuracy: 0.9723\n","Epoch 00024: val_loss improved from 15.55540 to 15.42916, saving model to Bert_123.h5\n","718/718 [==============================] - 687s 956ms/step - loss: 1.1219 - sparse_categorical_accuracy: 0.9723 - val_loss: 15.4292 - val_sparse_categorical_accuracy: 0.1654\n","Epoch 25/25\n","718/718 [==============================] - ETA: 0s - loss: 0.8604 - sparse_categorical_accuracy: 0.9827\n","Epoch 00025: val_loss improved from 15.42916 to 15.35121, saving model to Bert_123.h5\n","718/718 [==============================] - 686s 956ms/step - loss: 0.8604 - sparse_categorical_accuracy: 0.9827 - val_loss: 15.3512 - val_sparse_categorical_accuracy: 0.1662\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OxGaGJbvwQS","executionInfo":{"status":"ok","timestamp":1622755599264,"user_tz":300,"elapsed":136,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"4a8b8c41-5ce3-4983-cdb2-da940da66027"},"source":["bert_model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3face33350>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"U_70XCCqWDWI"},"source":["# Model Evaluation and Prediction\n","\n","This notebook evaluates and makes predictions with models we trained.\n","1. CNN\n","2. ArcFace\n","3. Bert\n","4. ArcFace+Bert\n","\n","References: https://www.kaggle.com/ragnar123/unsupervised-baseline-arcface"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yy2ZkNnNuQ8e","executionInfo":{"status":"ok","timestamp":1622754947557,"user_tz":300,"elapsed":312,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"4d6d5883-1574-46ea-d781-0a041563119c"},"source":["import os \n","\n","# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n","# your files will be saved in your Google Drive!\n","\n","# the base Google Drive directory\n","root_dir = \"/content/drive/Shareddrives/\"\n","\n","# choose where you want your project files to be saved\n","project_folder = \"deep learning project/final_code\"\n","\n","def create_and_set_working_directory(project_folder):\n","  # check if your project folder exists. if not, it will be created.\n","  if os.path.isdir(root_dir + project_folder) == False:\n","    os.mkdir(root_dir + project_folder)\n","    print(root_dir + project_folder + ' did not exist but was created.')\n","\n","  # change the OS to use your project folder as the working directory\n","  os.chdir(root_dir + project_folder)\n","\n","  # create a test file to make sure it shows up in the right place\n","  !touch 'new_file_in_working_directory.txt'\n","  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n","        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n","\n","create_and_set_working_directory(project_folder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Your working directory was changed to /content/drive/Shareddrives/deep learning project/final_code\n","\n","An empty text file was created there. You can also run !pwd to confirm the current working directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P2IdzxjtWDWJ"},"source":["import re\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB3\n","from sklearn import metrics\n","#from tensorflow.keras import backend as K\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import util"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"diID4V3fWDWK"},"source":["## Parameters"]},{"cell_type":"code","metadata":{"id":"5VOHBmncWDWK"},"source":["TRAIN_CSV_PATH = '../../data/train.csv'\n","TRAIN_IMG_DIR = '../../data/train_images/'\n","ARCFACE_MODEL_PATH = './trained/arcface_best_epoch_512_42.h5'\n","CNN_MODEL_PATH = './trained/CNN.h5'\n","N_CLASSES = 11014\n","IMAGE_SIZE = [512,512]\n","BATCH_SIZE = 8\n","Bert_mdodel_path = '/content/drive/Shareddrives/deep learning project/final_code/bert_model'\n","AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DuCWTyzUWDWK"},"source":["## Function Definition"]},{"cell_type":"code","metadata":{"id":"22NUFh8TWDWK"},"source":["def get_dataset_csv():\n","    '''\n","    Read and prepare the tabular records\n","    '''\n","    train = pd.read_csv(TRAIN_CSV_PATH)\n","    tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n","    train['matches'] = train['label_group'].map(tmp)\n","    train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n","    img_paths = TRAIN_IMG_DIR + train['image']\n","        \n","    return train, img_paths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYLBkeO2WDWL"},"source":["def read_image(image):\n","    '''\n","    Parse an image\n","    '''\n","    image = tf.io.read_file(image)\n","    image = util.decode_image(image, IMAGE_SIZE)\n","    return image\n","\n","# Function to get our dataset that read images\n","def get_dataset_img(image):\n","    '''\n","    Read and prepare the image dataset\n","    '''\n","    dataset = tf.data.Dataset.from_tensor_slices(image)\n","    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzWwnksKWDWL"},"source":["def load_model(which='arcface'):\n","    '''\n","    Load pretrained image models\n","    '''\n","    \n","    assert(which=='arcface' or which=='cnn'), 'which==\\'arcface\\' or \\'cnn\\''\n","    \n","    if which == 'cnn':\n","        print('Reminder: image size = (224,224)')\n","        return tf.keras.models.load_model('./trained/CNN.h5')\n","    \n","    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n","    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n","    x = EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    \n","    margin = util.ArcMarginProduct(\n","        n_classes = N_CLASSES, \n","        s = 30, \n","        m = 0.5, \n","        name='head/arc_margin', \n","        dtype='float32'\n","    )\n","    \n","    x = margin([x, label])\n","\n","    output = tf.keras.layers.Softmax(dtype='float32')(x)\n","    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n","    model.load_weights(ARCFACE_MODEL_PATH)\n","    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GEUudQ9CWDWM"},"source":["def embed_images(img_paths, model):\n","    image_dataset = get_dataset_img(img_paths)\n","    image_embeddings = model.predict(image_dataset)   \n","    return image_embeddings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SbbCo_8WDWM"},"source":["def embed_titles(df, max_features = 15500):\n","    tfidf = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n","    text_embeddings = tfidf.fit_transform(df['title'])\n","    return text_embeddings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qeg8tzxhWDWM"},"source":["def nearest_neighbor(df, \n","                     embeddings, \n","                     thresholds = np.arange(0.3,0.6,0.01), \n","                     n_neighbors = 50):\n","    '''\n","    1. Performs knn, then find the best threshold\n","    2. Use the best threshold to make predictions\n","    '''\n","\n","    knn = NearestNeighbors(n_neighbors = n_neighbors, metric='cosine')\n","    knn.fit(embeddings)\n","    \n","    distances, indices = knn.kneighbors(embeddings)\n","    \n","    scores = []\n","    for threshold in thresholds:\n","        preds = []\n","        for k in range(embeddings.shape[0]):\n","            index_matches = np.where(distances[k,] < threshold)[0]\n","            id_matches = indices[k,index_matches]\n","            posting_ids = ' '.join(df['posting_id'].iloc[id_matches].values)\n","            preds.append(posting_ids)\n","        df['pred_matches'] = preds\n","        df['f1'] = util.f1_score(df['matches'], df['pred_matches'])\n","        score = df['f1'].mean()\n","        print(f'Threshold:{threshold} - F1: {score}')\n","        scores.append(score)\n","    df_thresholds = pd.DataFrame({'threshold':thresholds,'f1':scores})\n","    best_f1 = df_thresholds.f1.max()\n","    best_threshold = df_thresholds[df_thresholds.f1==best_f1].threshold.min()\n","    print('-'*100)\n","    print(f'The best threshold is {best_threshold} with an f1 of {best_f1}')\n","    \n","    best_preds = []\n","    for k in range(embeddings.shape[0]):\n","        index_matches = np.where(distances[k,] < best_threshold)[0]\n","        id_matches = indices[k,index_matches]\n","        posting_ids = df['posting_id'].iloc[id_matches].values\n","        best_preds.append(posting_ids)\n","    \n","    return df, best_threshold, best_f1, best_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SM6Y_GC2WDWN"},"source":["## Evaluate and Predict"]},{"cell_type":"code","metadata":{"id":"WS0nEG1gWDWN","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"error","timestamp":1622755015630,"user_tz":300,"elapsed":143,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"7e323ffd-bdcb-4277-f33d-84a3be4279b0"},"source":["df, img_paths = get_dataset_csv()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-01c320360116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Shareddrives/deep learning project/data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: get_dataset_csv() takes 0 positional arguments but 1 was given"]}]},{"cell_type":"code","metadata":{"id":"ApsPKp7pWDWO","colab":{"base_uri":"https://localhost:8080/","height":460},"executionInfo":{"status":"error","timestamp":1622755029962,"user_tz":300,"elapsed":5842,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"860dcdca-3f1f-46e6-f5f3-09d87337b0cb"},"source":["model = load_model('arcface')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n","43941888/43941136 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-6872d775bcab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arcface'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-8c712f675db4>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(which)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCFACE_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = './trained/arcface_best_epoch_512_42.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}]},{"cell_type":"code","metadata":{"id":"SzN7otAkWDWO","outputId":"633370f4-3c08-48aa-98bd-295bee340738"},"source":["# 00:06:00\n","image_embeddings = embed_images(img_paths, model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Image embeddings shape is (34250, 1536)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IZzFgbUvWDWO","outputId":"25629418-fa49-4e6b-8875-3244962e2203"},"source":["df, img_threshold, img_f1, img_preds = nearest_neighbor(df, \n","                                                        image_embeddings, \n","                                                        thresholds = np.arange(0.3,0.6,0.01))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Threshold:0.3 - F1: 0.807931808369746\n","Threshold:0.31 - F1: 0.815814757157693\n","Threshold:0.32 - F1: 0.8227750264643898\n","Threshold:0.33 - F1: 0.8296851575414907\n","Threshold:0.34 - F1: 0.836653371502557\n","Threshold:0.35000000000000003 - F1: 0.8435490339690283\n","Threshold:0.36000000000000004 - F1: 0.8497741344366871\n","Threshold:0.37000000000000005 - F1: 0.8565898347407793\n","Threshold:0.38000000000000006 - F1: 0.8629129501399706\n","Threshold:0.39000000000000007 - F1: 0.868926199591246\n","Threshold:0.4000000000000001 - F1: 0.8743222944555005\n","Threshold:0.4100000000000001 - F1: 0.8795463257153483\n","Threshold:0.4200000000000001 - F1: 0.8842590815368498\n","Threshold:0.4300000000000001 - F1: 0.8891689378633886\n","Threshold:0.4400000000000001 - F1: 0.8929264811939516\n","Threshold:0.4500000000000001 - F1: 0.8967264739132388\n","Threshold:0.46000000000000013 - F1: 0.9002619797067279\n","Threshold:0.47000000000000014 - F1: 0.9035653413378164\n","Threshold:0.48000000000000015 - F1: 0.9062124738966897\n","Threshold:0.49000000000000016 - F1: 0.9083074876303644\n","Threshold:0.5000000000000002 - F1: 0.9105297753551862\n","Threshold:0.5100000000000002 - F1: 0.9122337120730979\n","Threshold:0.5200000000000002 - F1: 0.913388375371431\n","Threshold:0.5300000000000002 - F1: 0.9142476209136989\n","Threshold:0.5400000000000003 - F1: 0.9143516216285833\n","Threshold:0.5500000000000003 - F1: 0.9136673155371456\n","Threshold:0.5600000000000003 - F1: 0.9125311418753185\n","Threshold:0.5700000000000003 - F1: 0.9104656881105845\n","Threshold:0.5800000000000003 - F1: 0.9075687918761338\n","Threshold:0.5900000000000003 - F1: 0.9033977183999147\n","----------------------------------------------------------------------------------------------------\n","The best threshold is 0.5400000000000003 with an f1 of 0.9143516216285833\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gmFNjFLbWDWP","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"error","timestamp":1622755086773,"user_tz":300,"elapsed":140,"user":{"displayName":"meredith Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzlEd6gkd9gGrovboTbzQ5kiVcP70aY35UTpVe=s64","userId":"00206712173479257052"}},"outputId":"ce3c5ec0-4a50-417e-f387-073bc4450911"},"source":["title_embeddings = bert_model(df)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-bfd74cc36104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitle_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'History' object is not callable"]}]},{"cell_type":"code","metadata":{"id":"liZ8-n3PWDWP","outputId":"b9e421c1-4a09-4eea-cf5b-54835c104103"},"source":["df, text_threshold, title_f1, title_preds = nearest_neighbor(df, \n","                                                      title_embeddings, \n","                                                      thresholds = np.arange(0.3,0.6,0.01))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Threshold:0.3 - F1: 0.630776547251398\n","Threshold:0.31 - F1: 0.6352270544040849\n","Threshold:0.32 - F1: 0.6385704191694083\n","Threshold:0.33 - F1: 0.6425737224521486\n","Threshold:0.34 - F1: 0.6461641669803598\n","Threshold:0.35000000000000003 - F1: 0.6496528451842519\n","Threshold:0.36000000000000004 - F1: 0.653089439006744\n","Threshold:0.37000000000000005 - F1: 0.6557794983689451\n","Threshold:0.38000000000000006 - F1: 0.6579680043339512\n","Threshold:0.39000000000000007 - F1: 0.6598584657763932\n","Threshold:0.4000000000000001 - F1: 0.6616317472597671\n","Threshold:0.4100000000000001 - F1: 0.6635153361547791\n","Threshold:0.4200000000000001 - F1: 0.6651819166264529\n","Threshold:0.4300000000000001 - F1: 0.6659392906886799\n","Threshold:0.4400000000000001 - F1: 0.6660580341009082\n","Threshold:0.4500000000000001 - F1: 0.6656979203004432\n","Threshold:0.46000000000000013 - F1: 0.6644144768688384\n","Threshold:0.47000000000000014 - F1: 0.6638981909620011\n","Threshold:0.48000000000000015 - F1: 0.6619719121488122\n","Threshold:0.49000000000000016 - F1: 0.6599119861469871\n","Threshold:0.5000000000000002 - F1: 0.6565343607031406\n","Threshold:0.5100000000000002 - F1: 0.6530940233152942\n","Threshold:0.5200000000000002 - F1: 0.6487327224216957\n","Threshold:0.5300000000000002 - F1: 0.6439416808546439\n","Threshold:0.5400000000000003 - F1: 0.6386301557106345\n","Threshold:0.5500000000000003 - F1: 0.6317908318321429\n","Threshold:0.5600000000000003 - F1: 0.6243050719020539\n","Threshold:0.5700000000000003 - F1: 0.6165415467790359\n","Threshold:0.5800000000000003 - F1: 0.6074322315812006\n","Threshold:0.5900000000000003 - F1: 0.5976332551735322\n","----------------------------------------------------------------------------------------------------\n","The best threshold is 0.4400000000000001 with an f1 of 0.6660580341009082\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d-8W9D-hWDWQ"},"source":["def combine_predictions(row):\n","    '''\n","    Combines image predictions and text predictions (through union)\n","    '''\n","    x = np.union1d(row['pred_img'], row['pred_title'])\n","    return ' '.join(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDCH7CyMWDWQ"},"source":["df['pred_img'] = img_preds\n","df['pred_title'] = title_preds\n","final_pred = df.apply(combine_predictions, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGbkBwj4WDWQ","outputId":"3839ef48-085d-46fe-a82a-288ad48dfba3"},"source":["df['f1'] = util.f1_score(df['matches'], final_pred)\n","score = df['f1'].mean()\n","print(f'ArcFace+tfidf f1: {score}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ArcFace+tfidf f1: 0.8397749437764472\n"],"name":"stdout"}]}]}